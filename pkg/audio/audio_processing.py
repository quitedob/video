# æ–‡ä»¶è·¯å¾„: pkg/audio/audio_processing.py
# æ–‡ä»¶ä½œç”¨: éŸ³é¢‘æå–ä¸ ASR æ¨ç†å°è£…ï¼ˆåŒ…å«æ¨¡å‹ä¸‹è½½ç›®å½•è°ƒæ•´ã€è®¾å¤‡å¼ºåˆ¶ä½¿ç”¨ã€å¥å£®çš„ç»“æœè§£æï¼‰
from __future__ import annotations

# === åŸºæœ¬è¯´æ˜ï¼ˆæ¯ä¸ªä»£ç å—ä¸Šæ–¹æ·»åŠ çŸ­ä¸­æ–‡æ³¨é‡Šï¼‰ ===
# å¯¼å…¥ä¸ç±»å‹æ³¨è§£
from dataclasses import dataclass
from datetime import timedelta
from pathlib import Path
from typing import List, Dict, Optional, Any, Callable
import os
import json
import traceback
import wave
import subprocess
import logging
import threading
import queue
import time
import numpy as np

# è®¾ç½®æ—¥å¿—æ ¼å¼
logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s: %(message)s")
logger = logging.getLogger(__name__)

# ---- å®ç”¨å‡½æ•°ï¼šè·å–éŸ³é¢‘æ—¶é•¿ ----
def get_audio_duration(audio_path: str) -> float:
    """è·å–éŸ³é¢‘æ–‡ä»¶æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œä¼˜å…ˆä½¿ç”¨ waveï¼Œå¤±è´¥å›é€€åˆ° ffprobe"""
    audio_path = Path(audio_path)
    if audio_path.suffix.lower() == '.wav':
        try:
            with wave.open(str(audio_path), 'rb') as wav_file:
                frames = wav_file.getnframes()
                rate = wav_file.getframerate()
                return frames / float(rate)
        except Exception:
            pass
    try:
        cmd = ['ffprobe', '-v', 'quiet', '-print_format', 'json', '-show_format', str(audio_path)]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        data = json.loads(result.stdout)
        return float(data['format']['duration'])
    except Exception as e:
        logger.warning(f"æ— æ³•è·å–éŸ³é¢‘æ—¶é•¿ {audio_path}: {e}")
        return 0.0




# ---- GPU å¯ç”¨æ€§æ£€æµ‹å‡½æ•° ----
def check_gpu_availability_and_memory(min_memory_gb: float = 4.0) -> tuple[str, bool, dict]:
    """
    æ£€æµ‹GPUå¯ç”¨æ€§å’Œå†…å­˜ï¼ŒåŸºäºFunASRå®˜æ–¹æœ€ä½³å®è·µ

    å‚æ•°:
        min_memory_gb: æœ€å°GPUå†…å­˜è¦æ±‚ï¼ˆGBï¼‰ï¼Œé»˜è®¤4GB

    è¿”å›:
        tuple: (è®¾å¤‡å­—ç¬¦ä¸², æ˜¯å¦å¯ç”¨, è¯¦ç»†ä¿¡æ¯å­—å…¸)
    """
    gpu_info = {
        'gpu_available': False,
        'gpu_count': 0,
        'gpu_memory_total': 0,
        'gpu_memory_free': 0,
        'gpu_name': '',
        'cuda_version': '',
        'torch_version': '',
        'fallback_reason': '',
        'recommended_device': 'cpu'
    }

    try:
        import torch

        # è®°å½•ç‰ˆæœ¬ä¿¡æ¯
        gpu_info['torch_version'] = torch.__version__
        gpu_info['cuda_version'] = torch.version.cuda or "N/A"

        # åŸºç¡€GPUå¯ç”¨æ€§æ£€æŸ¥
        if not torch.cuda.is_available():
            gpu_info['fallback_reason'] = 'torch.cuda.is_available() è¿”å› False'
            logger.info("ğŸ” GPUæ£€æµ‹ç»“æœ: CUDAä¸å¯ç”¨")
            return "cpu", False, gpu_info

        # GPUæ•°é‡æ£€æŸ¥
        gpu_info['gpu_count'] = torch.cuda.device_count()
        if gpu_info['gpu_count'] == 0:
            gpu_info['fallback_reason'] = 'æœªæ£€æµ‹åˆ°GPUè®¾å¤‡'
            logger.info("ğŸ” GPUæ£€æµ‹ç»“æœ: æ— GPUè®¾å¤‡")
            return "cpu", False, gpu_info

        # å°è¯•ä½¿ç”¨ç¬¬ä¸€ä¸ªGPUè®¾å¤‡
        try:
            device_id = 0
            device = f"cuda:{device_id}"

            # è·å–GPUå±æ€§å’Œå†…å­˜ä¿¡æ¯
            gpu_props = torch.cuda.get_device_properties(device_id)
            gpu_info['gpu_name'] = gpu_props.name
            gpu_info['gpu_memory_total'] = gpu_props.total_memory / (1024**3)  # GB

            # æµ‹è¯•GPUæ˜¯å¦çœŸçš„å¯ä»¥å·¥ä½œï¼ˆåˆ†é…å°‘é‡å†…å­˜ï¼‰
            test_tensor = torch.randn(1000, device=device)
            del test_tensor
            torch.cuda.empty_cache()

            # è·å–å½“å‰å¯ç”¨å†…å­˜
            gpu_info['gpu_memory_free'] = (torch.cuda.get_device_properties(device_id).total_memory -
                                         torch.cuda.memory_allocated(device_id)) / (1024**3)

            # æ£€æŸ¥å†…å­˜æ˜¯å¦æ»¡è¶³æœ€å°è¦æ±‚
            if gpu_info['gpu_memory_free'] < min_memory_gb:
                gpu_info['fallback_reason'] = f'GPUå†…å­˜ä¸è¶³ï¼Œå½“å‰å¯ç”¨ {gpu_info["gpu_memory_free"]:.2f}GBï¼Œè¦æ±‚è‡³å°‘ {min_memory_gb}GB'
                logger.warning(f"âš ï¸ GPUå†…å­˜ä¸è¶³: {gpu_info['fallback_reason']}")
                return "cpu", False, gpu_info

            # æ‰€æœ‰æ£€æŸ¥é€šè¿‡
            gpu_info['gpu_available'] = True
            gpu_info['recommended_device'] = device
            logger.info(f"âœ… GPUæ£€æµ‹æˆåŠŸ: {gpu_info['gpu_name']}, å¯ç”¨å†…å­˜ {gpu_info['gpu_memory_free']:.2f}GB")
            return device, True, gpu_info

        except RuntimeError as e:
            gpu_info['fallback_reason'] = f'GPUè¿è¡Œæ—¶é”™è¯¯: {str(e)}'
            logger.warning(f"âš ï¸ GPUè¿è¡Œæ—¶é”™è¯¯: {e}")
            return "cpu", False, gpu_info

    except ImportError:
        gpu_info['fallback_reason'] = 'PyTorchæœªå®‰è£…'
        logger.error("âŒ PyTorchæœªå®‰è£…")
        return "cpu", False, gpu_info
    except Exception as e:
        gpu_info['fallback_reason'] = f'æ£€æµ‹è¿‡ç¨‹å¼‚å¸¸: {str(e)}'
        logger.error(f"âŒ GPUæ£€æµ‹å¼‚å¸¸: {e}")
        return "cpu", False, gpu_info

# ---- ASR é…ç½®æ•°æ®ç±» ----
@dataclass
class AsrConfig:
    """ASR å‚æ•°é…ç½®"""
    model_dir: str = "iic/SenseVoiceSmall"    # modelscope æ¨¡å‹ id æˆ–æœ¬åœ°è·¯å¾„
    device: str = "auto"                      # è®¾å¤‡ 'auto', 'cuda:0', 'cpu' ç­‰
    trust_remote_code: bool = True
    remote_code: Optional[str] = "./model.py"
    vad_kwargs: Optional[dict] = None
    batch_size_s: int = 30
    merge_length_s: int = 5
    merge_vad: bool = True
    use_itn: bool = True
    min_gpu_memory_gb: float = 4.0           # æœ€å°GPUå†…å­˜è¦æ±‚ï¼ˆGBï¼‰

# ---- å†…éƒ¨ï¼šè§£æ AutoModel / Pipeline è¿”å›ç»“æœ ----
def _parse_asr_result(raw_res: Any) -> str:
    """
    è§£æ FunASR / ModelScope è¿”å›ç»“æœï¼Œæ”¯æŒå¤šç§ç»“æ„ï¼š
    - åˆ—è¡¨å½¢å¼ï¼š [ { 'text': '...' , ... }, ... ]
    - å­—å…¸å½¢å¼ï¼š { 'text': '...', 'segments': [...], 'sentence_info': [...] }
    è¿”å›æ‹¼æ¥åçš„æ–‡æœ¬ï¼ˆç»è¿‡ç®€å•åå¤„ç†è°ƒç”¨ rich_transcription_postprocess å¦‚æœå¯ç”¨ï¼‰
    """
    text_parts: List[str] = []

    try:
        # è‹¥æ˜¯åˆ—è¡¨å¹¶ä¸”ç¬¬ä¸€ä¸ªå…ƒç´ ä¸º dict ä¸”å« text å­—æ®µ
        if isinstance(raw_res, list):
            for item in raw_res:
                if isinstance(item, dict):
                    t = item.get('text') or item.get('output') or item.get('sentence', '')
                    if isinstance(t, str) and t.strip():
                        text_parts.append(t.strip())
                elif isinstance(item, str):
                    text_parts.append(item.strip())

        # è‹¥æ˜¯ dictï¼Œå°è¯•å¤šè·¯å¾„è§£æ
        elif isinstance(raw_res, dict):
            # å¸¸è§å­—æ®µ
            if 'text' in raw_res and isinstance(raw_res['text'], str):
                text_parts.append(raw_res['text'].strip())
            # æœ‰ segments / sentence_info
            if 'segments' in raw_res and isinstance(raw_res['segments'], list):
                for seg in raw_res['segments']:
                    if isinstance(seg, dict):
                        t = seg.get('text') or seg.get('content') or ''
                        if isinstance(t, str) and t.strip():
                            text_parts.append(t.strip())
            if 'sentence_info' in raw_res and isinstance(raw_res['sentence_info'], list):
                for s in raw_res['sentence_info']:
                    if isinstance(s, dict):
                        t = s.get('text') or s.get('sentence')
                        if isinstance(t, str) and t.strip():
                            text_parts.append(t.strip())
        else:
            # å…œåº•ï¼šå­—ç¬¦ä¸²
            if isinstance(raw_res, str) and raw_res.strip():
                text_parts.append(raw_res.strip())

    except Exception:
        logger.warning("è§£æ ASR åŸå§‹ç»“æœæ—¶æŠ¥é”™ï¼Œå°è¯•ç›´æ¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²ã€‚")
        try:
            text_parts.append(str(raw_res))
        except Exception:
            pass

    # åˆå¹¶å¹¶è¿”å›
    joined = " ".join([p for p in text_parts if p])
    # é¢å¤–åå¤„ç†ï¼ˆè‹¥å¯ç”¨ï¼‰
    try:
        # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…æœªå®‰è£… funasr æ—¶æŠ›é”™
        from funasr.utils.postprocess_utils import rich_transcription_postprocess
        if joined:
            return rich_transcription_postprocess(joined)
    except Exception:
        pass

    return joined

# ---- åˆ›å»º/åŠ è½½ ASR æ¨¡å‹ï¼ˆå«æ¨¡å‹ä¸‹è½½ç›®å½•é‡å®šå‘ä¸è®¾å¤‡æ£€æŸ¥ï¼‰ ----
def create_asr_model(cfg: AsrConfig):
    """
    åˆ›å»ºå¹¶è¿”å› FunASR AutoModelï¼ˆä¼˜å…ˆï¼‰æˆ–å›é€€ ModelScope pipelineã€‚
    å˜åŒ–ç‚¹ï¼š
    - å°† ModelScope ä¸‹è½½ç¼“å­˜ç›®å½•é»˜è®¤è®¾ç½®åˆ°é¡¹ç›®æ ¹ä¸‹ model_cacheï¼ˆå¯é€šè¿‡ç¯å¢ƒå˜é‡ MODELSCOPE_CACHE è¦†ç›–ï¼‰
    - è°ƒç”¨ snapshot_download æ—¶ä½¿ç”¨ cache_dir å‚æ•°ï¼Œé¿å…ä¸‹è½½åˆ°ç³»ç»Ÿç”¨æˆ·ç›®å½•
    - åœ¨åˆ›å»ºæ¨¡å‹å‰æ£€æŸ¥å¹¶æç¤º GPU å¯ç”¨æ€§
    """
    # --- 1) ç¡®ä¿ MODELSCOPE_CACHE åœ¨å¯¼å…¥ modelscope å‰è®¾ç½®ï¼ˆä¼˜å…ˆä½¿ç”¨ç”¨æˆ·è®¾ç½®ï¼‰ ---
    try:
        project_root = Path(__file__).resolve().parents[2]  # d:\python\video\pkg -> project root ä¸ºä¸Šä¸¤çº§
        default_cache = project_root / "model_cache"
        # åªæœ‰å½“ç”¨æˆ·æ²¡æœ‰è‡ªå·±è®¾ç½® MODELSCOPE_CACHE æ—¶æ‰è®¾ç½®é»˜è®¤
        if not os.environ.get("MODELSCOPE_CACHE"):
            os.environ["MODELSCOPE_CACHE"] = str(default_cache)
            logger.info(f"MODELSCOPE_CACHE æœªè®¾ç½®ï¼Œå·²å°† modelscope ç¼“å­˜ç›®å½•è®¾ç½®ä¸º: {os.environ['MODELSCOPE_CACHE']}")
        else:
            logger.info(f"MODELSCOPE_CACHE å·²å­˜åœ¨: {os.environ.get('MODELSCOPE_CACHE')}")
    except Exception:
        logger.warning("è®¾ç½® MODELSCOPE_CACHE æ—¶å‡ºé”™ï¼Œç»§ç»­ä½¿ç”¨ç³»ç»Ÿé»˜è®¤ç¼“å­˜è·¯å¾„ã€‚")

    # --- 2) å¢å¼ºçš„GPUå¯ç”¨æ€§æ£€æµ‹ä¸è®¾å¤‡é€‰æ‹© ---
    logger.info("ğŸ” å¼€å§‹è¿›è¡ŒGPUå¯ç”¨æ€§æ£€æµ‹...")

    # ä½¿ç”¨æ–°çš„GPUæ£€æµ‹å‡½æ•°
    if cfg.device == "auto":
        # è‡ªåŠ¨æ¨¡å¼ï¼šä½¿ç”¨æ–°çš„æ£€æµ‹å‡½æ•°
        recommended_device, gpu_available, gpu_info = check_gpu_availability_and_memory(cfg.min_gpu_memory_gb)
        cfg.device = recommended_device

        if gpu_available:
            logger.info(f"ğŸ”¥ è‡ªåŠ¨é€‰æ‹©å¹¶æˆåŠŸé…ç½®GPU: {gpu_info['gpu_name']}")
            logger.info(f"ğŸ“Š GPUä¿¡æ¯ - æ€»å†…å­˜: {gpu_info['gpu_memory_total']:.2f}GB, "
                       f"å¯ç”¨å†…å­˜: {gpu_info['gpu_memory_free']:.2f}GB")
        else:
            logger.info(f"ğŸ’» GPUä¸å¯ç”¨ï¼Œè‡ªåŠ¨ä½¿ç”¨CPUå¤„ç†")
            logger.info(f"ğŸ“ å›é€€åŸå› : {gpu_info['fallback_reason']}")
    else:
        # æ‰‹åŠ¨æŒ‡å®šè®¾å¤‡æ¨¡å¼ï¼šéªŒè¯æŒ‡å®šè®¾å¤‡æ˜¯å¦å¯ç”¨
        if cfg.device.startswith("cuda"):
            logger.info(f"ğŸ” éªŒè¯ç”¨æˆ·æŒ‡å®šçš„è®¾å¤‡: {cfg.device}")
            recommended_device, gpu_available, gpu_info = check_gpu_availability_and_memory(cfg.min_gpu_memory_gb)

            if not gpu_available:
                logger.warning(f"âš ï¸ ç”¨æˆ·æŒ‡å®šçš„è®¾å¤‡ {cfg.device} ä¸å¯ç”¨")
                logger.warning(f"ğŸ“ åŸå› : {gpu_info['fallback_reason']}")
                logger.info(f"ğŸ”„ è‡ªåŠ¨å›é€€åˆ°CPUè®¾å¤‡")
                cfg.device = "cpu"
            else:
                logger.info(f"âœ… ç”¨æˆ·æŒ‡å®šçš„è®¾å¤‡ {cfg.device} å¯ç”¨")
                logger.info(f"ğŸ“Š GPUä¿¡æ¯: {gpu_info['gpu_name']}, "
                           f"å¯ç”¨å†…å­˜: {gpu_info['gpu_memory_free']:.2f}GB")
        elif cfg.device != "cpu":
            logger.warning(f"âš ï¸ æœªçŸ¥è®¾å¤‡ç±»å‹: {cfg.device}ï¼Œå›é€€åˆ°CPU")
            cfg.device = "cpu"

    logger.info(f"ğŸ“± æœ€ç»ˆä½¿ç”¨çš„è®¾å¤‡: {cfg.device}")

    # æ˜¾ç¤ºè¯¦ç»†çš„ç³»ç»Ÿä¿¡æ¯ï¼ˆä»…åœ¨GPUå¯ç”¨æ—¶ï¼‰
    if cfg.device.startswith("cuda"):
        try:
            import torch
            logger.info(f"ğŸ”§ ç³»ç»Ÿä¿¡æ¯ - PyTorch: {torch.__version__}, CUDA: {torch.version.cuda}")
        except Exception:
            pass

    # --- 3) å¦‚æœ model_dir çœ‹èµ·æ¥ä¸æ˜¯æœ¬åœ°è·¯å¾„ï¼Œåˆ™ä½¿ç”¨ modelscope.snapshot_download ä¸‹è½½åˆ°æœ¬åœ° cache_dir ---
    local_model_dir = cfg.model_dir
    try:
        from pathlib import Path as _P
        from modelscope import snapshot_download
        path_candidate = _P(local_model_dir)
        if not path_candidate.exists():
            logger.info(f"æ¨¡å‹ç›®å½• '{local_model_dir}' æœªåœ¨æœ¬åœ°æ‰¾åˆ°ï¼Œå°è¯•ä½¿ç”¨ modelscope.snapshot_download ä¸‹è½½ï¼ˆcache_dir å·²æŒ‡å‘ MODELSCOPE_CACHEï¼‰...")
            try:
                # ä½¿ç”¨ cache_dir æ˜ç¡®æ§åˆ¶ä¸‹è½½ä½ç½®ï¼ˆmodelscope æ”¯æŒ cache_dir å‚æ•°ï¼‰
                cache_dir = os.environ.get("MODELSCOPE_CACHE")
                local_model_dir = snapshot_download(local_model_dir, cache_dir=cache_dir)
                logger.info(f"æ¨¡å‹å·²ä¸‹è½½åˆ°: {local_model_dir}")
            except TypeError:
                # å…¼å®¹æ—§ç‰ˆ snapshot_download å¯èƒ½ä¸æ”¯æŒ cache_dir å‚æ•°
                local_model_dir = snapshot_download(local_model_dir)
                logger.info(f"æ¨¡å‹å·²ä¸‹è½½åˆ° (fallback): {local_model_dir}")
            except Exception as e:
                logger.warning(f"modelscope.snapshot_download å¤±è´¥: {e}; å°†ç»§ç»­ä½¿ç”¨åŸå§‹è·¯å¾„ï¼ˆå¯èƒ½ AutoModel å¯ç›´æ¥å¤„ç†è¿œç¨‹ idï¼‰")
                local_model_dir = cfg.model_dir
        else:
            local_model_dir = str(path_candidate)
    except Exception as e:
        logger.warning(f"æ— æ³•ä½¿ç”¨ modelscope ä¸‹è½½æ¨¡å‹ï¼ˆç»§ç»­ä½¿ç”¨åŸè·¯å¾„ï¼‰ï¼Œé”™è¯¯: {e}")
        local_model_dir = cfg.model_dir

    # --- 4) å¦‚æœæœ¬åœ°ç›®å½•ä¸­å­˜åœ¨ model.pyï¼Œåˆ™æŠŠ remote_code æŒ‡å‘è¯¥æ–‡ä»¶ ---
    remote_code_path = None
    try:
        cand = Path(local_model_dir)
        if cand.is_dir():
            model_py = cand / "model.py"
            if model_py.exists():
                remote_code_path = str(model_py)
                logger.info(f"æ‰¾åˆ°æœ¬åœ° model.pyï¼Œremote_code æŒ‡å‘ï¼š{remote_code_path}")
    except Exception:
        remote_code_path = cfg.remote_code

    # --- 5) å°è¯•æ„é€  FunASR AutoModelï¼ˆé¦–é€‰ï¼‰ ---
    try:
        from funasr import AutoModel
        am = AutoModel(
            model=local_model_dir,
            trust_remote_code=cfg.trust_remote_code,
            remote_code=remote_code_path or cfg.remote_code,
            vad_model="fsmn-vad",
            vad_kwargs=cfg.vad_kwargs or {"max_single_segment_time": 6000000},
            device=cfg.device,
            disable_update=True,
        )
        logger.info("âœ… AutoModel åˆå§‹åŒ–æˆåŠŸ")
        return am
    except Exception as e:
        logger.error("âŒ AutoModel åˆå§‹åŒ–å¤±è´¥ï¼Œå¼€å§‹å›é€€æµç¨‹ï¼ˆModelScope pipelineï¼‰:")
        traceback.print_exc()

    # --- 6) å›é€€åˆ° ModelScope pipelineï¼ˆæ›´å¯é ä½†åŠŸèƒ½å—é™ï¼‰ ---
    try:
        from modelscope.pipelines import pipeline
        from modelscope.utils.constant import Tasks
        logger.info("å°è¯•ä½¿ç”¨ ModelScope pipeline å›é€€å¯åŠ¨æ¨¡å‹...")
        pipeline_model = pipeline(task=Tasks.auto_speech_recognition, model=cfg.model_dir, device=cfg.device)
        logger.info("âœ… ModelScope pipeline åˆå§‹åŒ–æˆåŠŸ")
        return pipeline_model
    except Exception:
        logger.error("âŒ ModelScope pipeline å›é€€ä¹Ÿå¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ/ä¾èµ–/æ¨¡å‹ id")
        traceback.print_exc()
        raise RuntimeError("æ— æ³•åˆå§‹åŒ– ASR æ¨¡å‹ï¼ˆAutoModel ä¸ pipeline å‡å¤±è´¥ï¼‰")

# ---- éŸ³é¢‘åˆ†æ®µï¼ˆæ”¯æŒé•¿éŸ³é¢‘åˆ†ç‰‡ï¼‰ ----
def split_audio_to_segments(audio_path: str, segment_duration_minutes: int) -> list:
    """å°†éŸ³é¢‘åˆ‡åˆ†ä¸ºè‹¥å¹²æ®µï¼ˆç”¨äºé•¿éŸ³é¢‘ï¼‰"""
    segments = []
    try:
        with wave.open(audio_path, 'rb') as wav_file:
            sample_rate = wav_file.getframerate()
            duration_seconds = wav_file.getnframes() / sample_rate
        segment_duration_seconds = segment_duration_minutes * 60
        total_segments = int(duration_seconds // segment_duration_seconds) + 1
        for i in range(total_segments):
            start_time = i * segment_duration_seconds
            end_time = min((i + 1) * segment_duration_seconds, duration_seconds)
            if end_time - start_time < 1:
                break
            segments.append({
                'index': i,
                'start_time': start_time,
                'end_time': end_time,
                'duration': end_time - start_time
            })
        return segments
    except Exception as e:
        logger.error(f"éŸ³é¢‘åˆ†æ®µå¤±è´¥: {e}")
        return segments

# ---- å¯¹å•ä¸ªåˆ†æ®µæˆ–æ–‡ä»¶è¿›è¡Œ ASR æ¨ç†å¹¶è¿”å›æ–‡æœ¬ ----
def transcribe_audio_segment(model: Any, audio_path: str, cfg: AsrConfig) -> str:
    """
    å¯¹å•ä¸ªéŸ³é¢‘æ–‡ä»¶æˆ–åˆ†å‰²ç‰‡æ®µåšæ¨ç†ï¼ˆå…¼å®¹ AutoModel å’Œ ModelScope pipelineï¼‰ã€‚
    è¿”å›ï¼šè¯†åˆ«åˆ°çš„æ–‡æœ¬ï¼ˆå­—ç¬¦ä¸²ï¼‰
    """
    logger.info(f"å¼€å§‹å¤„ç†éŸ³é¢‘æ–‡ä»¶: {audio_path}")
    try:
        # AutoModel æœ‰ generate æ–¹æ³•ï¼› pipeline å¯¹è±¡å¯ç›´æ¥è°ƒç”¨
        if hasattr(model, "generate"):
            # AutoModel.generate çš„è¿”å›å¯èƒ½æ˜¯ list/dict/è‡ªå®šä¹‰ç»“æ„ï¼Œå–å raw_res
            raw_res = model.generate(
                input=str(audio_path),
                cache={},
                language="auto",
                use_itn=cfg.use_itn,
                batch_size_s=cfg.batch_size_s,
                merge_vad=cfg.merge_vad,
                merge_length_s=cfg.merge_length_s,
            )
            # FunASR è¿”å›å¯èƒ½ä¸º [ { 'key':'...', 'text':'...' } , ... ]
            # è§£æä¸ºå­—ç¬¦ä¸²
            parsed = _parse_asr_result(raw_res)
            logger.info(f"åˆ†æ®µè¯†åˆ«ç»“æœï¼ˆæˆªæ–­æ˜¾ç¤ºï¼‰: {parsed[:200]}")
            return parsed
        else:
            # pipeline æƒ…å†µï¼šç›´æ¥ä¼ è·¯å¾„
            raw_res = model(str(audio_path))
            parsed = _parse_asr_result(raw_res)
            logger.info(f"pipeline è¿”å›ç»“æœï¼ˆæˆªæ–­æ˜¾ç¤ºï¼‰: {parsed[:200]}")
            return parsed
    except Exception as e:
        logger.error(f"éŸ³é¢‘æ¨ç†å¤±è´¥: {e}")
        traceback.print_exc()
        return ""

# ---- æ‰¹é‡åˆ†æ®µæ¨ç†ï¼ˆå¯¹æ–‡ä»¶ç›®å½•æˆ–å·²ç»åˆ‡å¥½çš„ç‰‡æ®µé€æ®µè¯†åˆ«ï¼‰ ----
def transcribe_audio_segments(model: Any, audio_files: List[str], cfg: AsrConfig) -> Dict[str, Any]:
    """
    æ‰¹é‡è¯†åˆ«å¤šä¸ªéŸ³é¢‘ç‰‡æ®µï¼ˆaudio_files ä¸ºç‰‡æ®µè·¯å¾„åˆ—è¡¨ï¼‰
    è¿”å›ç»“æ„: { 'total_segments': n, 'texts': [ ... ], 'joined_text': '...' }
    """
    texts = []
    total_speech_seconds = 0.0
    for fp in audio_files:
        text = transcribe_audio_segment(model, fp, cfg)
        texts.append({'file': fp, 'text': text})
        # ç»Ÿè®¡å¤„ç†æ—¶é•¿ï¼ˆå°è¯•è·å–ç‰‡æ®µæ—¶é•¿ï¼‰
        try:
            dur = get_audio_duration(fp)
            total_speech_seconds += dur
        except Exception:
            pass

    joined = " ".join([t['text'] for t in texts if t['text']])
    return {
        'total_segments': len(audio_files),
        'texts': texts,
        'joined_text': joined,
        'time_speech': total_speech_seconds
    }

# ---- é¢å¤–å·¥å…·ï¼šå‘½ä»¤è¡Œ/è„šæœ¬å¯åŠ¨æ—¶å¼ºåˆ¶ GPU çš„å»ºè®® ----
# æç¤ºï¼šå¦‚æœä½ æƒ³åœ¨è„šæœ¬å¤–éƒ¨å¼ºåˆ¶å“ªä¸ª GPU å¯è§ï¼Œè¯·åœ¨å¯åŠ¨ç¨‹åºå‰è®¾ç½®ï¼š
# åœ¨ Windows cmd: set CUDA_VISIBLE_DEVICES=0 && python app.py
# åœ¨ Linux/mac:   CUDA_VISIBLE_DEVICES=0 python app.py
# æ³¨æ„ï¼šå¿…é¡»åœ¨ import torch ä¹‹å‰è®¾ç½®æœ¬ç¯å¢ƒå˜é‡ï¼Œå¦åˆ™å¯èƒ½æ— æ•ˆã€‚


# =====================================================
# æ–°çš„æµå¼ASRæ¶æ„å®ç°ï¼ˆåŸºäºç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å¼ï¼‰
# =====================================================

class FfmpegProducer(threading.Thread):
    """FFmpegç”Ÿäº§è€…çº¿ç¨‹ï¼šä»åª’ä½“æ–‡ä»¶æµå¼è¯»å–éŸ³é¢‘æ•°æ®å¹¶æ”¾å…¥é˜Ÿåˆ—"""

    def __init__(self, media_path: str, audio_queue: queue.Queue, chunk_size: int = 3840000,
                 progress_callback: Optional[Callable] = None):
        """
        åˆå§‹åŒ–FFmpegç”Ÿäº§è€…

        å‚æ•°:
            media_path: åª’ä½“æ–‡ä»¶è·¯å¾„
            audio_queue: çº¿ç¨‹å®‰å…¨é˜Ÿåˆ—ç”¨äºæ•°æ®ä¼ è¾“
            chunk_size: éŸ³é¢‘æ•°æ®å—å¤§å°ï¼ˆå­—èŠ‚ï¼‰ï¼Œé»˜è®¤2åˆ†é’Ÿ16kHzå•å£°é“æ•°æ®
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
        """
        super().__init__(daemon=True)
        self.media_path = media_path
        self.audio_queue = audio_queue
        self.chunk_size = chunk_size
        self.progress_callback = progress_callback
        self.stop_event = threading.Event()
        self.process = None
        self.logger = logging.getLogger(__name__)

    def run(self):
        """è¿è¡Œç”Ÿäº§è€…çº¿ç¨‹"""
        try:
            print(f"[FFmpeg] ç”Ÿäº§è€…çº¿ç¨‹å¯åŠ¨ï¼Œåª’ä½“æ–‡ä»¶: {self.media_path}")
            # æ„å»ºFFmpegå‘½ä»¤ï¼šæµå¼è¾“å‡ºåˆ°stdout
            cmd = [
                'ffmpeg', '-i', self.media_path,
                '-vn',  # æ— è§†é¢‘æµ
                '-acodec', 'pcm_s16le',  # 16ä½PCMç¼–ç 
                '-ar', '16000',  # 16kHzé‡‡æ ·ç‡
                '-ac', '1',  # å•å£°é“
                '-f', 's16le',  # åŸå§‹PCMæ ¼å¼
                'pipe:1'  # è¾“å‡ºåˆ°stdoutç®¡é“
            ]

            self.logger.info(f"å¯åŠ¨FFmpegè¿›ç¨‹: {' '.join(cmd)}")

            # å¯åŠ¨FFmpegè¿›ç¨‹
            self.process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                bufsize=self.chunk_size
            )

            # è¯»å–æµæ•°æ®å¹¶æ”¾å…¥é˜Ÿåˆ—
            while not self.stop_event.is_set():
                if self.process.poll() is not None:
                    # è¿›ç¨‹å·²ç»“æŸ
                    break

                # ä»FFmpeg stdoutè¯»å–æ•°æ®å—
                data = self.process.stdout.read(self.chunk_size)
                if not data:
                    break

                # å°†æ•°æ®å—æ”¾å…¥é˜Ÿåˆ—
                try:
                    self.audio_queue.put(data, timeout=1.0)
                    if self.progress_callback:
                        self.progress_callback(0, "éŸ³é¢‘æ•°æ®æµä¼ è¾“ä¸­...")
                except queue.Full:
                    self.logger.warning("é˜Ÿåˆ—å·²æ»¡ï¼Œè·³è¿‡æ•°æ®å—")
                    continue

            # å‘é€ç»“æŸä¿¡å·
            try:
                self.audio_queue.put(None, timeout=1.0)  # Noneä½œä¸ºç»“æŸæ ‡è®°
            except queue.Full:
                pass

            print(f"[FFmpeg] ç”Ÿäº§è€…çº¿ç¨‹ç»“æŸ")
            self.logger.info("FFmpegç”Ÿäº§è€…çº¿ç¨‹ç»“æŸ")

        except Exception as e:
            self.logger.error(f"FFmpegç”Ÿäº§è€…é”™è¯¯: {e}")
            try:
                self.audio_queue.put(None, timeout=1.0)  # å‘é€é”™è¯¯ç»“æŸä¿¡å·
            except queue.Full:
                pass
        finally:
            if self.process and self.process.poll() is None:
                self.process.terminate()
                self.process.wait()

    def stop(self):
        """åœæ­¢ç”Ÿäº§è€…çº¿ç¨‹"""
        self.stop_event.set()
        if self.process and self.process.poll() is None:
            self.process.terminate()
            self.process.wait()


class AsrConsumer(threading.Thread):
    """ASRæ¶ˆè´¹è€…çº¿ç¨‹ï¼šä»é˜Ÿåˆ—è·å–éŸ³é¢‘æ•°æ®å¹¶è¿›è¡Œå®æ—¶è½¬å†™"""

    def __init__(self, task_id: str, audio_queue: queue.Queue, model: Any,
                 asr_config: AsrConfig, socketio: Any, result_callback: Optional[Callable] = None):
        """
        åˆå§‹åŒ–ASRæ¶ˆè´¹è€…

        å‚æ•°:
            task_id: ä»»åŠ¡ID
            audio_queue: çº¿ç¨‹å®‰å…¨é˜Ÿåˆ—
            model: ASRæ¨¡å‹å®ä¾‹
            asr_config: ASRé…ç½®
            socketio: SocketIOå®ä¾‹ç”¨äºå®æ—¶é€šä¿¡
            result_callback: ç»“æœå›è°ƒå‡½æ•°
        """
        super().__init__(daemon=True)
        self.task_id = task_id
        self.audio_queue = audio_queue
        self.model = model
        self.asr_config = asr_config
        self.socketio = socketio
        self.result_callback = result_callback
        self.stop_event = threading.Event()
        self.logger = logging.getLogger(__name__)
        self.chunk_count = 0

    def run(self):
        """è¿è¡Œæ¶ˆè´¹è€…çº¿ç¨‹"""
        try:
            print(f"[ASR] æ¶ˆè´¹è€…çº¿ç¨‹å¯åŠ¨ï¼Œä»»åŠ¡ID: {self.task_id}, socketioç±»å‹: {type(self.socketio)}")
            self.logger.info(f"ASRæ¶ˆè´¹è€…çº¿ç¨‹å¯åŠ¨ï¼Œä»»åŠ¡ID: {self.task_id}")

            while not self.stop_event.is_set():
                try:
                    # ä»é˜Ÿåˆ—è·å–æ•°æ®å—ï¼ˆé˜»å¡ç­‰å¾…ï¼‰
                    data = self.audio_queue.get(timeout=1.0)
                    if data is None:  # ç»“æŸä¿¡å·
                        break

                    self.chunk_count += 1

                    # å°†bytesè½¬æ¢ä¸ºnumpyæ•°ç»„
                    audio_array = np.frombuffer(data, dtype=np.int16).astype(np.float32) / 32768.0

                    # æ‰§è¡ŒASRæ¨ç†
                    try:
                        print(f"[ASR] å¼€å§‹å¤„ç†éŸ³é¢‘å— {self.chunk_count}ï¼Œæ•°æ®é•¿åº¦: {len(audio_array)}")
                        if hasattr(self.model, "generate"):
                            # FunASR AutoModel
                            print(f"[ASR] ä½¿ç”¨FunASR AutoModelï¼Œå‚æ•°: use_itn={self.asr_config.use_itn}, batch_size_s={self.asr_config.batch_size_s}")
                            raw_result = self.model.generate(
                                input=audio_array,
                                cache={},
                                language="auto",
                                use_itn=self.asr_config.use_itn,
                                batch_size_s=self.asr_config.batch_size_s,
                                merge_vad=self.asr_config.merge_vad,
                                merge_length_s=self.asr_config.merge_length_s,
                            )
                        else:
                            # ModelScope pipeline
                            print(f"[ASR] ä½¿ç”¨ModelScope pipeline")
                            raw_result = self.model(audio_array)

                        print(f"[ASR] æ¨ç†å®Œæˆï¼Œç»“æœç±»å‹: {type(raw_result)}")

                        # è§£æç»“æœ
                        text = self._parse_asr_result(raw_result)
                        print(f"[ASR] æ–‡æœ¬è§£æå®Œæˆï¼Œæ–‡æœ¬é•¿åº¦: {len(text)}")

                        if text.strip():  # åªæœ‰éç©ºæ–‡æœ¬æ‰å‘é€
                            print(f"[ASR] è¯†åˆ«åˆ°æ–‡æœ¬: '{text[:100]}...' (é•¿åº¦: {len(text)})")
                            # å®æ—¶å‘é€è½¬å†™ç»“æœ
                            self._emit_transcript_chunk(text)

                            # ä¿å­˜åˆ°ç»“æœæ–‡ä»¶
                            if self.result_callback:
                                self.result_callback(text)
                        else:
                            print(f"[ASR] æ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡å‘é€")

                    except Exception as e:
                        self.logger.error(f"ASRæ¨ç†å¤±è´¥: {e}")
                        continue

                except queue.Empty:
                    continue
                except Exception as e:
                    self.logger.error(f"æ¶ˆè´¹è€…å¤„ç†é”™è¯¯: {e}")
                    continue

            print(f"[ASR] æ¶ˆè´¹è€…çº¿ç¨‹ç»“æŸï¼Œä»»åŠ¡ID: {self.task_id}")
            self.logger.info(f"ASRæ¶ˆè´¹è€…çº¿ç¨‹ç»“æŸï¼Œä»»åŠ¡ID: {self.task_id}")

        except Exception as e:
            self.logger.error(f"ASRæ¶ˆè´¹è€…çº¿ç¨‹å¼‚å¸¸: {e}")
        finally:
            # å‘é€æµç»“æŸäº‹ä»¶
            try:
                print(f"[ASR] å‘é€æµç»“æŸäº‹ä»¶: task_id={self.task_id}, socketio={type(self.socketio)}")

                if self.socketio is None:
                    print(f"[ASR] âŒ socketioä¸ºNoneï¼Œæ— æ³•å‘é€ç»“æŸäº‹ä»¶")
                else:
                    self.socketio.emit('asr_stream_end', {
                        'task_id': self.task_id,
                        'message': 'å¤„ç†å®Œæˆ'
                    })
                    print(f"[ASR] âœ… æµç»“æŸäº‹ä»¶å·²å‘é€")
            except Exception as e:
                self.logger.error(f"å‘é€ç»“æŸäº‹ä»¶å¤±è´¥: {e}")
                print(f"[ASR] âŒ å‘é€ç»“æŸäº‹ä»¶å¼‚å¸¸: {e}")

    def _parse_asr_result(self, raw_result: Any) -> str:
        """è§£æASRç»“æœ"""
        text_parts = []

        try:
            if isinstance(raw_result, list):
                for item in raw_result:
                    if isinstance(item, dict):
                        text = item.get('text', '')
                        if text.strip():
                            text_parts.append(text.strip())
            elif isinstance(raw_result, dict):
                if 'text' in raw_result:
                    text_parts.append(raw_result['text'].strip())
            else:
                text_parts.append(str(raw_result).strip())
        except Exception as e:
            self.logger.warning(f"è§£æASRç»“æœå¤±è´¥: {e}")

        return ' '.join(text_parts)

    def _emit_transcript_chunk(self, text: str, is_final: bool = False):
        """
        åœ¨åå°çº¿ç¨‹ä¸­å‘å‰ç«¯å‘é€è¯†åˆ«åˆ°çš„æ–‡æœ¬å—ã€‚
        - æ˜¾å¼æŒ‡å®š namespace="/"ï¼Œé¿å…åå°çº¿ç¨‹é»˜è®¤å‘½åç©ºé—´ä¸ä¸€è‡´å¯¼è‡´å®¢æˆ·ç«¯æ”¶ä¸åˆ°äº‹ä»¶
        - å‘é€å‰å…ˆæ¸…ç† SenseVoice çš„å¯Œæ–‡æœ¬æ ‡è®°ï¼ˆå¦‚ <|zh|>ã€<|withitn|> ç­‰ï¼‰
        - ç»§ç»­æºå¸¦ task_idï¼Œå‰ç«¯å¯æ ¡éªŒæ˜¯å¦å½“å‰ä»»åŠ¡
        """
        import re  # ç®€çŸ­ä¸­æ–‡æ³¨é‡Šï¼šç”¨äºæ­£åˆ™æ¸…ç†ç‰¹æ®Šæ ‡è®°

        try:
            # ç®€çŸ­ä¸­æ–‡æ³¨é‡Šï¼šå¥å£®æ€§æ£€æŸ¥ï¼Œç¡®ä¿ socketio å­˜åœ¨
            if self.socketio is None:
                print("[ASR] âŒ socketio ä¸º Noneï¼Œæ— æ³•å‘é€è½¬å†™å—")
                return

            # ç®€çŸ­ä¸­æ–‡æ³¨é‡Šï¼šæ¸…ç† <|...|> å½¢å¼çš„å¯Œæ–‡æœ¬æ ‡ç­¾ï¼Œå¹¶æŠ˜å å¤šä½™ç©ºç™½
            # ä¾‹ï¼š<|zh|><|NEUTRAL|><|Speech|><|withitn|> â†’ ""
            cleaned = re.sub(r"<\|[^|>]+?\|>", "", text or "")
            cleaned = re.sub(r"\s+", " ", cleaned).strip()

            # æ·»åŠ è°ƒè¯•æ—¥å¿—
            print(f"[ASR] å‘é€è½¬å†™å—: task_id={self.task_id}, åŸå§‹é•¿åº¦={len(text)}, æ¸…æ´—åé•¿åº¦={len(cleaned)}, socketio={type(self.socketio)}")

            payload = {
                "task_id": self.task_id,   # ç®€çŸ­ä¸­æ–‡æ³¨é‡Šï¼šç”¨äºå‰ç«¯ä»»åŠ¡åŒ¹é…
                "text": cleaned,           # ç®€çŸ­ä¸­æ–‡æ³¨é‡Šï¼šå·²æ¸…æ´—æ–‡æœ¬
                "is_final": bool(is_final)
            }

            # ç®€çŸ­ä¸­æ–‡æ³¨é‡Šï¼šæ˜¾å¼æŒ‡å®š namespace="/"; åå°çº¿ç¨‹ emit åœ¨æŸäº›æ¨¡å¼ä¸‹ä¸æŒ‡å®šä¼šè¢«å®¢æˆ·ç«¯æ”¶ä¸åˆ°
            self.socketio.emit('asr_transcript_chunk', payload, namespace="/")
            print(f"[ASR] âœ… è½¬å†™å—å·²å‘é€: {len(cleaned)} å­—ç¬¦ (å·²æ¸…æ´—)")
        except Exception as e:
            self.logger.error(f"å‘é€è½¬å†™ç»“æœå¤±è´¥: {e}")
            print(f"[ASR] âŒ å‘é€è½¬å†™ç»“æœå¼‚å¸¸: {e}")

    def stop(self):
        """åœæ­¢æ¶ˆè´¹è€…çº¿ç¨‹"""
        self.stop_event.set()


class StreamingAsrProcessor:
    """æµå¼ASRå¤„ç†å™¨ï¼šåè°ƒç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…çš„ä¸»æ§åˆ¶å™¨"""

    def __init__(self, socketio: Any):
        """
        åˆå§‹åŒ–æµå¼ASRå¤„ç†å™¨

        å‚æ•°:
            socketio: SocketIOå®ä¾‹ç”¨äºé€šä¿¡
        """
        self.socketio = socketio
        self.active_tasks = {}  # ä»»åŠ¡çŠ¶æ€å­˜å‚¨
        self.logger = logging.getLogger(__name__)

    def start_streaming_asr(self, task_id: str, media_path: str,
                           asr_config: AsrConfig, device: str = 'auto') -> bool:
        """
        å¯åŠ¨æµå¼ASRå¤„ç†

        å‚æ•°:
            task_id: ä»»åŠ¡ID
            media_path: åª’ä½“æ–‡ä»¶è·¯å¾„
            asr_config: ASRé…ç½®
            device: è®¡ç®—è®¾å¤‡

        è¿”å›:
            bool: æ˜¯å¦æˆåŠŸå¯åŠ¨
        """
        try:
            # åˆ›å»ºASRæ¨¡å‹
            model = create_asr_model(asr_config)
            if not model:
                raise Exception("ASRæ¨¡å‹åˆ›å»ºå¤±è´¥")

            # åˆ›å»ºçº¿ç¨‹å®‰å…¨é˜Ÿåˆ—
            audio_queue = queue.Queue(maxsize=5)  # æœ‰ç•Œé˜Ÿåˆ—é˜²æ­¢å†…å­˜æº¢å‡º

            # åˆ›å»ºç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…çº¿ç¨‹
            producer = FfmpegProducer(
                media_path=media_path,
                audio_queue=audio_queue,
                progress_callback=lambda p, m: self._emit_progress(task_id, p, m)
            )

            consumer = AsrConsumer(
                task_id=task_id,
                audio_queue=audio_queue,
                model=model,
                asr_config=asr_config,
                socketio=self.socketio,
                result_callback=lambda text: self._save_result_chunk(task_id, text)
            )

            # å­˜å‚¨ä»»åŠ¡ä¿¡æ¯
            self.active_tasks[task_id] = {
                'status': 'processing',
                'media_path': media_path,
                'producer': producer,
                'consumer': consumer,
                'audio_queue': audio_queue,
                'result_text': [],
                'start_time': time.time()
            }

            # å¯åŠ¨çº¿ç¨‹
            print(f"[ASR] å¯åŠ¨ç”Ÿäº§è€…çº¿ç¨‹: {producer}")
            producer.start()
            print(f"[ASR] ç”Ÿäº§è€…çº¿ç¨‹çŠ¶æ€: {producer.is_alive()}")

            print(f"[ASR] å¯åŠ¨æ¶ˆè´¹è€…çº¿ç¨‹: {consumer}")
            consumer.start()
            print(f"[ASR] æ¶ˆè´¹è€…çº¿ç¨‹çŠ¶æ€: {consumer.is_alive()}")

            # å‘é€ä»»åŠ¡åˆ›å»ºäº‹ä»¶ï¼ˆä¿®å¤ï¼šæ·»åŠ namespace="/"ï¼‰
            print(f"[ASR] å‘é€asr_task_createdäº‹ä»¶ï¼Œtask_id: {task_id}")
            self.socketio.emit('asr_task_created', {
                'task_id': task_id,
                'message': 'æµå¼ASRä»»åŠ¡å·²åˆ›å»ºï¼Œå¼€å§‹å¤„ç†...'
            }, namespace="/")
            print(f"[ASR] asr_task_createdäº‹ä»¶å·²å‘é€")

            self.logger.info(f"æµå¼ASRä»»åŠ¡å¯åŠ¨æˆåŠŸ: {task_id}")
            print(f"[ASR] æµå¼ASRä»»åŠ¡å¯åŠ¨å®Œæˆï¼Œtask_id: {task_id}")
            return True

        except Exception as e:
            self.logger.error(f"å¯åŠ¨æµå¼ASRå¤±è´¥: {e}")
            self._emit_error(task_id, str(e))
            return False

    def stop_task(self, task_id: str):
        """åœæ­¢æŒ‡å®šä»»åŠ¡"""
        if task_id in self.active_tasks:
            task_info = self.active_tasks[task_id]

            # åœæ­¢çº¿ç¨‹
            if task_info['producer'].is_alive():
                task_info['producer'].stop()

            if task_info['consumer'].is_alive():
                task_info['consumer'].stop()

            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            task_info['status'] = 'stopped'
            self._emit_progress(task_id, 100, 'ä»»åŠ¡å·²åœæ­¢')

    def get_task_status(self, task_id: str) -> dict:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        if task_id not in self.active_tasks:
            return {'status': 'not_found'}

        task_info = self.active_tasks[task_id]
        return {
            'status': task_info['status'],
            'chunks_processed': len(task_info['result_text']),
            'duration': time.time() - task_info['start_time']
        }

    def _emit_progress(self, task_id: str, progress: int, message: str):
        """å‘é€è¿›åº¦äº‹ä»¶"""
        try:
            self.socketio.emit('asr_progress', {
                'task_id': task_id,
                'progress': progress,
                'message': message
            })
        except Exception as e:
            self.logger.error(f"å‘é€è¿›åº¦äº‹ä»¶å¤±è´¥: {e}")

    def _emit_error(self, task_id: str, error: str):
        """å‘é€é”™è¯¯äº‹ä»¶"""
        try:
            self.socketio.emit('asr_error', {
                'task_id': task_id,
                'error': error
            })
        except Exception as e:
            self.logger.error(f"å‘é€é”™è¯¯äº‹ä»¶å¤±è´¥: {e}")

    def _save_result_chunk(self, task_id: str, text: str):
        """ä¿å­˜ç»“æœå—åˆ°ä»»åŠ¡ä¿¡æ¯"""
        if task_id in self.active_tasks:
            self.active_tasks[task_id]['result_text'].append(text)

    def get_full_result(self, task_id: str) -> str:
        """è·å–å®Œæ•´ç»“æœ"""
        if task_id in self.active_tasks:
            return ' '.join(self.active_tasks[task_id]['result_text'])
        return ""